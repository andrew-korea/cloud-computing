{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing from MongoDB Database 1 to MongoDB Database 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.103:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>YouTube Trending Videos Analysis and Prediction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11ef2a6d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# stop the SparkSession created automatically (by the time the notebook is running, cannot change much in that session's configuration)\n",
    "# [Ref]https://www.edureka.co/community/5268/how-to-change-the-spark-session-configuration-in-pyspark\n",
    "spark.sparkContext.stop() \n",
    "# create a new SparkSession and connect to MongoDB database & collection\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"YouTube Trending Videos Analysis and Prediction\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb+srv://gp15:MSBD5003gp15@cluster0.3ygtx.mongodb.net/Database0.US_videos\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb+srv://gp15:MSBD5003gp15@cluster0.qfnff.mongodb.net/Database0.US_pre\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark # check if sparksession created successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- comments_disabled: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- ratings_disabled: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- video_error_or_removed: string (nullable = true)\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('trending_date','title','channel_title',\n",
    "               'category_id', 'publish_time','tags','views',\n",
    "               'likes','dislikes','comment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|publish_time            |\n",
      "+------------------------+\n",
      "|2017-11-13T07:30:00.000Z|\n",
      "|2017-11-12T18:01:41.000Z|\n",
      "|2017-11-13T17:13:01.000Z|\n",
      "|2017-11-12T05:37:17.000Z|\n",
      "|2017-11-13T14:00:23.000Z|\n",
      "|2017-11-13T13:45:16.000Z|\n",
      "|2017-11-13T02:05:26.000Z|\n",
      "|2017-11-13T03:00:00.000Z|\n",
      "|2017-11-13T17:00:00.000Z|\n",
      "|2017-11-12T14:00:00.000Z|\n",
      "|2017-11-12T18:30:01.000Z|\n",
      "|2017-11-13T20:09:58.000Z|\n",
      "|2017-11-12T17:00:05.000Z|\n",
      "|2017-11-13T19:07:23.000Z|\n",
      "|2017-11-13T16:00:07.000Z|\n",
      "|2017-11-13T11:00:04.000Z|\n",
      "|2017-11-13T15:30:17.000Z|\n",
      "|2017-11-12T22:00:01.000Z|\n",
      "|2017-11-13T14:00:03.000Z|\n",
      "|2017-11-12T15:00:01.000Z|\n",
      "+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('publish_time').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[trending_date: string, title: string, channel_title: string, category_id: int, publish_time: string, tags: string, views: int, likes: int, dislikes: int, comment_count: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col , column\n",
    "cols=['category_id','views','likes','dislikes','comment_count']\n",
    "for col in cols:\n",
    "    df=df.withColumn('%s'%col ,df[col].cast('int'))\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "|summary|             views|            likes|          dislikes|     comment_count|\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "|  count|             40949|            40949|             40949|             40949|\n",
      "|   mean|2360784.6382573447| 74266.7024347359| 3711.400888910596| 8446.803682629612|\n",
      "| stddev| 7394113.759703929|228885.3382094995|29029.705945001806|37430.486994379804|\n",
      "|    min|               549|                0|                 0|                 0|\n",
      "|    max|         225211923|          5613827|           1674420|           1361580|\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('views','likes','dislikes','comment_count').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+--------------------+------------------------+-----------------+--------------------+------------------------+\n",
      "|summary|trending_date|               title|           channel_title|      category_id|        publish_time|                    tags|\n",
      "+-------+-------------+--------------------+------------------------+-----------------+--------------------+------------------------+\n",
      "|  count|        40949|               40949|                   40949|            40949|               40949|                   40949|\n",
      "|   mean|         null|               435.0|                    null|19.97242911914821|                null|                    null|\n",
      "| stddev|         null|                 0.0|                    null|7.568326828280466|                null|                    null|\n",
      "|    min|     17.01.12|#184 Making a PCB...|                 12 News|                1|2006-07-23T08:24:...|    #MeToo|\"Grammys 2...|\n",
      "|    max|     18.31.05|üò± $1,145 iPhone ...|ÏòÅÍµ≠ÎÇ®Ïûê Korean Engli...|               43|2018-06-14T01:31:...|Ï¢ÖÌòÑ|\"ÌÉúÏó∞\"|\"jonghyun...|\n",
      "+-------+-------------+--------------------+------------------------+-----------------+--------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('trending_date','title','channel_title','category_id', 'publish_time','tags').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull\n",
    "# Êü•ËØ¢ÊüêÂàó‰∏∫nullÁöÑË°åÊï∞\n",
    "cols = ['trending_date','title','channel_title',\n",
    "        'category_id', 'publish_time','tags','views',\n",
    "        'likes','dislikes','comment_count']\n",
    "for col in cols:\n",
    "    print(df.filter(isnull('%s'%col)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40949"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(thresh=10).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=df.dropna(thresh=10)\n",
    "# df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40901"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1„ÄÅÂà†ÂéªÂÆåÂÖ®ÈáçÂ§çÁöÑË°å\n",
    "df2 = df.dropDuplicates() \n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40898"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.Âà†Èô§Êüê‰∫õÂÖ≥ÈîÆÂ≠óÊÆµÂÄºÂÆåÂÖ®Áõ∏ÂêåÁöÑËÆ∞ÂΩïÔºåsubsetÂèÇÊï∞ÂÆö‰πâËøô‰∫õÂ≠óÊÆµ\n",
    "df2 = df2.dropDuplicates(subset = \n",
    "                         [c for c in df2.columns if c in ['channel_title','likes', 'dislikes','views','comment_count']])\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'views': [-1737579.5, 3485976.5],\n",
       " 'likes': [-56319.0, 107129.0],\n",
       " 'dislikes': [-1931.5, 3712.5],\n",
       " 'comment_count': [-5664.0, 10944.0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['views', 'likes', 'dislikes','comment_count']\n",
    "bounds = {}\n",
    "\n",
    "for col in cols:\n",
    "    quantiles = df2.approxQuantile(\n",
    "        col, [0.25, 0.75], 0.05\n",
    "    )\n",
    "    \n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    \n",
    "    bounds[col] = [\n",
    "        quantiles[0] - 1.5 * IQR,\n",
    "        quantiles[1] + 1.5 * IQR\n",
    "    ]\n",
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+\n",
      "|category_id|channel_title        |\n",
      "+-----------+---------------------+\n",
      "|25         |CBS New York         |\n",
      "|24         |Looper               |\n",
      "|26         |First We Feast       |\n",
      "|23         |Smosh                |\n",
      "|10         |carrieunderwoodVEVO  |\n",
      "|24         |RM Videos            |\n",
      "|23         |jacksfilms           |\n",
      "|22         |FOX Soccer           |\n",
      "|26         |Clevver Style        |\n",
      "|24         |TheEllenShow         |\n",
      "|15         |AntsCanada           |\n",
      "|10         |Alan Walker          |\n",
      "|10         |DopeBoyTroy          |\n",
      "|28         |MinuteEarth          |\n",
      "|15         |camelsandfriends     |\n",
      "|24         |KTVU                 |\n",
      "|24         |Warner Bros. Pictures|\n",
      "|24         |Gibi ASMR            |\n",
      "|17         |Philadelphia 76ers   |\n",
      "|10         |R3HAB                |\n",
      "+-----------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('category_id','channel_title').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = spark.read.format(\"mongo\").option(\"uri\", \"mongodb+srv://gp15:MSBD5003gp15@cluster0.3ygtx.mongodb.net/Database0.US_videos_cat\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = spark.read.json('./US_category_id.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---+\n",
      "|title                |id |\n",
      "+---------------------+---+\n",
      "|Film & Animation     |1  |\n",
      "|Autos & Vehicles     |2  |\n",
      "|Music                |10 |\n",
      "|Pets & Animals       |15 |\n",
      "|Sports               |17 |\n",
      "|Short Movies         |18 |\n",
      "|Travel & Events      |19 |\n",
      "|Gaming               |20 |\n",
      "|Videoblogging        |21 |\n",
      "|People & Blogs       |22 |\n",
      "|Comedy               |23 |\n",
      "|Entertainment        |24 |\n",
      "|News & Politics      |25 |\n",
      "|Howto & Style        |26 |\n",
      "|Education            |27 |\n",
      "|Science & Technology |28 |\n",
      "|Nonprofits & Activism|29 |\n",
      "|Movies               |30 |\n",
      "|Anime/Animation      |31 |\n",
      "|Action/Adventure     |32 |\n",
      "+---------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# j = spark.read.option(\"multiLine\",\"true\").json('./US_category_id.json')\n",
    "\n",
    "# Explode Array to Structure\n",
    "explodej = j.withColumn('Exp_RESULTS',F.explode(F.col('items'))).drop('items')\n",
    "\n",
    "# Read location and name\n",
    "dfj = explodej.select(\"Exp_RESULTS.snippet.title\",'Exp_RESULTS.id')\n",
    "dfj.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj=dfj.withColumnRenamed('id','category_id')\n",
    "dfj=dfj.withColumnRenamed('title','category_title')     # Â∞ÜtitleÈáçÂëΩÂêç‰∏∫category_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|      category_title|category_id|\n",
      "+--------------------+-----------+\n",
      "|    Film & Animation|          1|\n",
      "|    Autos & Vehicles|          2|\n",
      "|               Music|         10|\n",
      "|      Pets & Animals|         15|\n",
      "|              Sports|         17|\n",
      "|        Short Movies|         18|\n",
      "|     Travel & Events|         19|\n",
      "|              Gaming|         20|\n",
      "|       Videoblogging|         21|\n",
      "|      People & Blogs|         22|\n",
      "|              Comedy|         23|\n",
      "|       Entertainment|         24|\n",
      "|     News & Politics|         25|\n",
      "|       Howto & Style|         26|\n",
      "|           Education|         27|\n",
      "|Science & Technology|         28|\n",
      "|Nonprofits & Acti...|         29|\n",
      "|              Movies|         30|\n",
      "|     Anime/Animation|         31|\n",
      "|    Action/Adventure|         32|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.join(dfj, 'category_id', \"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+\n",
      "|category_id|       channel_title|               title|      category_title|\n",
      "+-----------+--------------------+--------------------+--------------------+\n",
      "|         28|      Dennis Kapatos|01/24/2018 - Falc...|Science & Technology|\n",
      "|         28|     Because Science|The Most Toxic Ki...|Science & Technology|\n",
      "|         28|Hydraulic Press C...|Crushing and Slic...|Science & Technology|\n",
      "|         28|         MinuteEarth|Why You Shouldn't...|Science & Technology|\n",
      "|         28|            PBS Eons|How the Squid Los...|Science & Technology|\n",
      "|         28|         AsapSCIENCE|What If Your Airp...|Science & Technology|\n",
      "|         28|  CrazyRussianHacker|6 Cheese Gadgets ...|Science & Technology|\n",
      "|         28|       the Hacksmith|Make it Real: HUL...|Science & Technology|\n",
      "|         28|           The Verge|Android P first look|Science & Technology|\n",
      "|         28|         MinuteEarth|Milk Is Just Filt...|Science & Technology|\n",
      "|         28|     Because Science|Why You Don't Act...|Science & Technology|\n",
      "|         28|   Google Developers|Keynote (Google I...|Science & Technology|\n",
      "|         28|        RetroManCave|Commodore 64 | A ...|Science & Technology|\n",
      "|         28|      Dawid Szmandra|LEGO Liebherr LR ...|Science & Technology|\n",
      "|         28|            PBS Eons|How the Turtle Go...|Science & Technology|\n",
      "|         28|        Austin Evans|The Weirdest Myst...|Science & Technology|\n",
      "|         28|       Strange Parts|Inside a Chinese ...|Science & Technology|\n",
      "|         28|       UrAvgConsumer|BEST Black Friday...|Science & Technology|\n",
      "|         28|       the Hacksmith|Make it Real: HUL...|Science & Technology|\n",
      "|         28|              SpaceX|Falcon Heavy & St...|Science & Technology|\n",
      "+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select('category_id','channel_title','title','category_title').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- category_title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.write.format(\"mongo\").mode(\"overwrite\").option(\"database\", \"Database0\").option(\"collection\", \"US_pre\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
